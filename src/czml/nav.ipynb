{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sanjog/devs/FCX/FCX-playground-BE/src/czml\n",
      "/home/sanjog/miniconda3/envs/itsc-fcx-n/lib/python310.zip\n",
      "/home/sanjog/miniconda3/envs/itsc-fcx-n/lib/python3.10\n",
      "/home/sanjog/miniconda3/envs/itsc-fcx-n/lib/python3.10/lib-dynload\n",
      "\n",
      "/home/sanjog/miniconda3/envs/itsc-fcx-n/lib/python3.10/site-packages\n",
      "../\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "for line in sys.path:\n",
    "     print(line)\n",
    "\n",
    "# sys.path.remove(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Generator\n",
    "\n",
    "from abstract.czml_data_process import CZMLDataProcess\n",
    "from utils.czml_writer_nav import NavCzmlWriter\n",
    "\n",
    "class NavCZMLDataProcess(CZMLDataProcess):\n",
    "  def __init__(self):    \n",
    "    pass\n",
    "  \n",
    "  def ingest(self, url: str) -> np.array:\n",
    "    s3_client = boto3.client('s3')\n",
    "    [bucket_name, objectKey] = self._get_s3_details(url)\n",
    "    s3_file = s3_client.get_object(Bucket=bucket_name, Key=objectKey)\n",
    "\n",
    "    file = s3_file['Body'].iter_lines()\n",
    "    \n",
    "    data = self._generator_to_np(file)\n",
    "    return data\n",
    "  \n",
    "  def preprocess(self, data: np.array) -> pd.DataFrame:\n",
    "    cleaned_data = self._cleaning(data)\n",
    "    transformed_data = self._transformation(cleaned_data)\n",
    "    integrated_data = self._integration(transformed_data)\n",
    "    return integrated_data\n",
    "\n",
    "  def prep_visualization(self, data: pd.DataFrame) -> str:\n",
    "    nav_czml_writer = NavCzmlWriter(data[\"length\"], data[\"time_window\"], data[\"time_steps\"], data[\"longitude\"], data[\"latitude\"], data[\"altitude\"], data[\"roll\"], data[\"pitch\"], data[\"heading\"])\n",
    "    nav_czml_str = nav_czml_writer.get_czml_string()\n",
    "    return nav_czml_str\n",
    "\n",
    "\n",
    "  # data preprocessing steps\n",
    "\n",
    "  def _cleaning(self, data: np.array) -> np.array:\n",
    "    col_index_map = self._get_col_index_map()\n",
    "    data = deepcopy(data)\n",
    "\n",
    "    # scrape necessary data columns \n",
    "    time = data[:, col_index_map[\"time\"]]\n",
    "    latitude = data[:, col_index_map[\"latitude\"]]\n",
    "    longitude = data[:, col_index_map[\"longitude\"]]\n",
    "    altitude = data[:, col_index_map[\"altitude\"]]\n",
    "    heading = data[:, col_index_map[\"heading\"]] * np.pi / 180. - np.pi / 2.\n",
    "    pitch = data[:, col_index_map[\"pitch\"]] * np.pi / 180.\n",
    "    roll = data[:, col_index_map[\"roll\"]] * np.pi / 180.\n",
    "    \n",
    "    # data masks\n",
    "    # remove nan values\n",
    "    mask = np.logical_not(np.isnan(latitude))\n",
    "    mask = np.logical_and(mask, np.logical_not(np.isnan(longitude)))\n",
    "    mask = np.logical_and(mask, np.logical_not(np.isnan(altitude)))\n",
    "    mask = np.logical_and(mask, np.logical_not(np.isnan(heading)))\n",
    "    mask = np.logical_and(mask, np.logical_not(np.isnan(pitch)))\n",
    "    mask = np.logical_and(mask, np.logical_not(np.isnan(roll)))\n",
    "    \n",
    "    # remove duplicate time values\n",
    "    _, unique_idx = np.unique(time, return_index=True)\n",
    "    unique = np.copy(mask)\n",
    "    unique[:] = False\n",
    "    unique[unique_idx] = True\n",
    "    mask = np.logical_and(mask, unique)\n",
    "    \n",
    "    # apply masks\n",
    "    time = time[mask].astype('datetime64[s]')\n",
    "    time_window = time[[0, -1]].astype(np.string_)\n",
    "    time_window = np.core.defchararray.add(time_window, np.string_('Z'))\n",
    "    \n",
    "    f_time_window = np.core.defchararray.decode(time_window, 'UTF-8')\n",
    "    f_time_steps = (time - time[0]).astype(int).tolist()[::5]\n",
    "    f_latitude = latitude[mask][::5]\n",
    "    f_longitude = longitude[mask][::5]\n",
    "    f_altitude = altitude[mask][::5]\n",
    "    f_heading = heading[mask][::5]\n",
    "    f_pitch = pitch[mask][::5]\n",
    "    f_roll = roll[mask][::5]\n",
    "    f_length = mask[mask][::5].size\n",
    "    \n",
    "    return np.hstack((f_time_window, f_time_steps, f_latitude, f_longitude, f_altitude, f_heading, f_pitch, f_roll, f_length))\n",
    "  \n",
    "  def _transformation(self, data: np.array) -> np.array:\n",
    "    #  no transformation needed\n",
    "    return data\n",
    "  \n",
    "  def _integration(self, data: np.array) -> pd.DataFrame:\n",
    "    # use data and create a dataframe\n",
    "    return pd.DataFrame(data=data, columns= [\"time_window\", \"time_steps\", \"latitude\", \"longitude\", \"altitude\", \"heading\", \"pitch\", \"roll\", \"length\"])\n",
    "\n",
    "  # utils\n",
    "\n",
    "  def _get_s3_details(self, url):\n",
    "    url = url.replace(\"s3://\", \"\")\n",
    "    temp_url = url.split(\"/\")\n",
    "    bucket_name = temp_url[0]\n",
    "    \n",
    "    temp_url = url.split(bucket_name+\"/\")\n",
    "    objectKey = temp_url[1]  # key should not start with /\n",
    "    return [bucket_name, objectKey]\n",
    "  \n",
    "  def _get_col_index_map(self):\n",
    "    return {\n",
    "        \"time\": 1,\n",
    "        \"latitude\": 2,\n",
    "        \"longitude\": 3,\n",
    "        \"altitude\": 4,\n",
    "        \"heading\": 14,\n",
    "        \"pitch\": 16,\n",
    "        \"roll\": 17\n",
    "    }\n",
    "    \n",
    "  def _generator_to_np(self, infile: Generator) -> np.array:\n",
    "    # As the data in txt is all string, to put it inside numpy array, we need to convert it to appropirate types\n",
    "    \n",
    "    # create null converters\n",
    "    converters = {}\n",
    "    for i in range(33): # 33 cols/feature data\n",
    "      converters[i] = lambda _: np.nan \n",
    "    \n",
    "    # upadate converters for appropriate faeture/cols with appropriate functions\n",
    "    col_index_map = self._get_col_index_map()\n",
    "    converters[col_index_map[\"time\"]] = lambda x: np.datetime64(x, 's').astype(np.int64)\n",
    "    converters[col_index_map[\"latitude\"]] = self._string_to_float\n",
    "    converters[col_index_map[\"longitude\"]] = self._string_to_float\n",
    "    converters[col_index_map[\"altitude\"]] = self._string_to_float\n",
    "    converters[col_index_map[\"heading\"]] = self._string_to_float\n",
    "    converters[col_index_map[\"pitch\"]] = self._string_to_float\n",
    "    converters[col_index_map[\"roll\"]] = self._string_to_float\n",
    "    \n",
    "    # apply converter during txt load\n",
    "    return np.loadtxt(infile, delimiter=',', converters=converters)\n",
    "  \n",
    "  def _string_to_float(self, str):\n",
    "        value = np.nan\n",
    "        try:\n",
    "            value = float(str)\n",
    "        except:\n",
    "            pass\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[           nan, 1.44709058e+09,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [           nan, 1.44709058e+09,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [           nan, 1.44709059e+09,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       ...,\n",
       "       [           nan, 1.44710637e+09,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [           nan, 1.44710637e+09,            nan, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [           nan, 1.44710637e+09,            nan, ...,\n",
       "                   nan,            nan,            nan]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = NavCZMLDataProcess()\n",
    "\n",
    "data = obj.ingest(\"s3://ghrc-fcx-field-campaigns-szg/Olympex/instrument-raw-data/nav_er2/data/olympex_naver2_IWG1_20151109-2159.txt\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itsc-fcx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
